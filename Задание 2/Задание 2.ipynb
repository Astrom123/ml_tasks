{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5HXTcR8_B9N"
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E09E83P4tJ5-"
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-x2ztJsm3RY"
   },
   "source": [
    "# **Подготовка данных**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KTK-DmGs194"
   },
   "source": [
    "Чистим данные. Удаляем из текста эмодзи, знаки пунктуации, и часто встречающийся символ \"\\xa0\". Представляем предложения в виде векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dOC7Hat60ZM"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "        u\"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U0001F1F2\"\n",
    "        u\"\\U0001F1F4\"\n",
    "        u\"\\U0001F620\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6Euay7V_B9a"
   },
   "outputs": [],
   "source": [
    "with open(\"train.json\", encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(\"test.json\", encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SdEtCdjZ_B9g"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(list(train_data.keys()), dtype='str')\n",
    "y_train = np.array(list(train_data.values()))\n",
    "\n",
    "X_test = np.array(list(test_data.keys()), dtype='str')\n",
    "y_test = np.array(list(test_data.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KbM8Gnbl5SEV"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'text': np.concatenate([X_train, X_test], axis=0), 'funny': np.concatenate([y_train, y_test], axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ioM0ZeYiR54H"
   },
   "outputs": [],
   "source": [
    "data.text = data.text.apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
    "data.text = data.text.apply(lambda x: x.replace(\"quote\", \" \"))\n",
    "data.text = data.text.apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8nPkKGwX7EJt"
   },
   "outputs": [],
   "source": [
    "X_train = data.text.values[:len(X_train)]\n",
    "y_train = data.funny.values[:len(X_train)]\n",
    "\n",
    "X_test = data.text.values[len(X_train):]\n",
    "y_test = data.funny.values[len(X_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Ekw7qIS_B-A"
   },
   "outputs": [],
   "source": [
    "filters = '!\"#$%&()+,-./:;<=>?@[\\]^*_`{|}~\\t\\n№…«»–”„☪●☼•—'\n",
    "tokenizer = Tokenizer(num_words=50000, filters=filters)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbDA0c8O_B-G"
   },
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cDcpB2Il_B-P",
    "outputId": "acc0545f-32c9-464d-ecc7-34e9e3c578ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylen = np.vectorize(len)\n",
    "maxlen = mylen(X_train).max()\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KlfwtMxc_B-W",
    "outputId": "12ed8fef-eb60-4860-9845-1f621983442e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238642"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "By_H4dUOnINR"
   },
   "source": [
    "# **Модель 1. Пара слоёв LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "RWA4MaWEG_H6",
    "outputId": "b8ab02c9-2fe3-4292-cd50-3f10cd31e4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 201132 samples, validate on 50284 samples\n",
      "Epoch 1/2\n",
      "201132/201132 [==============================] - 376s 2ms/step - loss: 0.4777 - acc: 0.7729 - f1_m: 0.7711 - val_loss: 0.4573 - val_acc: 0.7857 - val_f1_m: 0.7903\n",
      "Epoch 2/2\n",
      "201132/201132 [==============================] - 372s 2ms/step - loss: 0.3408 - acc: 0.8518 - f1_m: 0.8526 - val_loss: 0.4899 - val_acc: 0.7787 - val_f1_m: 0.7855\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Bidirectional(layers.LSTM(embedding_dim, return_sequences=True)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(128)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    shuffle=True,\n",
    "                    epochs=2,\n",
    "                    validation_split = 0.2,\n",
    "                    batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kw3aqXL7uZ8j"
   },
   "source": [
    "**Результат f1 score на тестовых данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "_rlLUWBAJKBM",
    "outputId": "5ff14c14-425b-4241-9673-78427530678b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61794/61794 [==============================] - 306s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7259800225996904"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = model.evaluate(X_test, y_test)[2]\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOmhW5BfnQMJ"
   },
   "source": [
    "# **Модель 2. CNN с фильтрами разного размера**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "iDgTPEuPm05j",
    "outputId": "e8933914-5ce5-460b-f2ae-44a1373c07cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 201132 samples, validate on 50284 samples\n",
      "Epoch 1/2\n",
      "201132/201132 [==============================] - 52s 259us/step - loss: 0.5546 - acc: 0.7378 - f1_m: 0.7397 - val_loss: 0.5001 - val_acc: 0.7736 - val_f1_m: 0.7796\n",
      "Epoch 2/2\n",
      "201132/201132 [==============================] - 49s 241us/step - loss: 0.3821 - acc: 0.8428 - f1_m: 0.8375 - val_loss: 0.4960 - val_acc: 0.7794 - val_f1_m: 0.7834\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "\n",
    "filter_sizes = [2, 3, 5, 7]\n",
    "conv_filters = []\n",
    "\n",
    "input_tensor = layers.Input(shape=(maxlen,))\n",
    "input_layer = layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)(input_tensor)\n",
    "\n",
    "for f_size in filter_sizes:\n",
    "    conv_filter = layers.Conv1D(128, f_size, activation='relu')(input_layer)\n",
    "    conv_filter = layers.GlobalMaxPooling1D()(conv_filter)\n",
    "    conv_filters.append(conv_filter)\n",
    "\n",
    "conc_layer=layers.Concatenate()(conv_filters)\n",
    "graph = Model(inputs=input_tensor, outputs=conc_layer)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(graph)\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(conv_filters), activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    shuffle=True,\n",
    "                    epochs=2,\n",
    "                    validation_split = 0.2,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXSh7NbeuvXX"
   },
   "source": [
    "**Результат f1 score на тестовых данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "NWoGAjTxJIOR",
    "outputId": "83d147f2-2136-4aeb-960e-10e8df16138e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61794/61794 [==============================] - 5s 73us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7204401534047448"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = model.evaluate(X_test, y_test)[2]\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukCLjSC07smm"
   },
   "source": [
    "# **Модель 3. Классический ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "5F0qJZEK7zx2",
    "outputId": "e90707b4-7e28-4ce3-bcd7-1a3d004687b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "clf = RFC(n_estimators = 100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eilpu3xXu1dF"
   },
   "source": [
    "**Результат f1 score на тестовых данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4X0rPki5Rlz2",
    "outputId": "ea7e0345-cbe1-4e14-f3b4-b98cb790a239"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.690649577628896"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
